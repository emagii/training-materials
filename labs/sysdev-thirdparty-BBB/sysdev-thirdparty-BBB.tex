\subchapter{Third party libraries and applications}{Objective: Learn
  how to leverage existing libraries and applications: how to
  configure, compile and install them}

To illustrate how to use existing libraries and applications, we will
extend the small root filesystem built in the {\em A tiny embedded
  system} lab to add the {\em DirectFB} graphic library and sample
applications using this library.

We'll see that manually re-using existing libraries is quite tedious,
so that more automated procedures are necessary to make it
easier. However, learning how to perform these operations manually
will significantly help you when you'll face issues with more
automated tools.

\section{Figuring out library dependencies}

As most libraries, DirectFB depends on other libraries, and these
dependencies are different depending on the configuration chosen for
DirectFB. In our case, we will enable support for:

\begin{itemize}
\item PNG image loading
\item JPEG image loading
\item Font rendering using a font engine
\end{itemize}

The PNG image loading feature will be provided by the {\em libpng}
library, the JPEG image loading feature by the {\em jpeg} library and
the font engine will be implemented by the {\em FreeType} library. The
{\em libpng} library itself depends on the {\em zlib}
compression/decompression library. So, we end up with the following
dependency tree:

\begin{center}
\includegraphics[width=\textwidth]{labs/sysdev-thirdparty-BBB/directfb-dependencies.pdf}
\end{center}

Of course, all these libraries rely on the C library, which is not
mentioned here, because it is already part of the root filesystem
built in the {\em A tiny embedded system} 
lab. You might wonder how to
figure out this dependency tree by yourself. Basically, there are
several ways, that can be combined:

\begin{itemize}
\item Read the library documentation, which often mentions the
  dependencies;
\item Read the help message of the configure script (by running
  \code{./configure --help}).
\item By running the configure script, compiling and looking at the
  errors.
\end{itemize}

To configure, compile and install all the components of our system,
we're going to start from the bottom of the tree with {\em zlib}, then
continue with {\em libpng}, \emph{jpeg} and \emph{FreeType}, to
finally compile \emph{DirectFB} and the \emph{DirectFB} sample
applications.

\clearpage
\section{Preparation}

For our cross-compilation work, we will need to separate spaces:
\begin{itemize}
\item A \emph{staging} space in which we will directly install all the
  packages: non-stripped versions of the libraries, headers,
  documentation and other files needed for the compilation. This
  \emph{staging} space can be quite big, but will not be used on our
  target, only for compiling libraries or applications;
\item A \emph{target} space, in which we will copy only the required
  files from the \emph{staging} space: binaries and libraries, after
  stripping \footnote{You may run into problems with write permission, when you are stripping
  in the target directory, so you may want to use a separate terminal window, running in supervisor
  more with the path setup to the toolchain}, configuration files needed at runtime, etc. This target
  space will take a lot less space than the \emph{staging} space, and
  it will contain only the files that are really needed to make the
  system work on the target.
\end{itemize}

To sum up, the {\em staging} space will contain everything that's
needed for compilation, while the {\em target} space will contain only
what's needed for execution.

In \code{$HOME/felabs/sysdev/thirdparty}, create the \code{staging} directories
and create a symbolic link from \code{target} to \code{/tftpboot/core-image-minimal}

For the target, we need a basic system with BusyBox, device nodes and
initialization scripts.
Since the kernel build we have done, has an issue with the framebuffer
we are going to use a better tested Yocto file system.

Unpack \code{ftp://ftp.emagii.com/pub/training/yocto/core-image-minimal-beaglebone.tar.bz2}
in \code{/tftpboot}.

\begin{verbatim}
cd /tftpboot
wget ftp://www.emagii.com/pub/training/yocto/core-image-minimal-beaglebone.tar.bz2
mkdir -p core-image-minimal
cd core-image-minimal
sudo tar --numeric-owner -jxvf ../core-image-minimal-beaglebone.tar.bz2
\end{verbatim}

It would be nice to track every change we do to the root filesystem,
so lets initialize a git repo inside the filesystem.

\begin{verbatim}
cd /tftpboot/core-image-minimal
git init
git add .
git commit -m "Initial Commit" -s
\end{verbatim}
ls /tftp	
We will also store the kernel and device tree file inside the filesystem in the \code{/boot} directory.

\begin{verbatim}
mkdir -p boot
cd boot
sudo wget ftp://ftp.emagii.com/pub/training/yocto/uImage
sudo wget ftp://ftp.emagii.com/pub/training/yocto/am335x-boneblack.dtb
\end{verbatim}

Check in the new files using \code{git}

To make it easy to use the directory, we will make a symbolic link to
this directory from the third party directory.

Go back to \code{$HOME/felabs/sysdev/thirdparty} and create a link.

\begin{verbatim}
ln -s /tftpboot/core-image-minimal target
\end{verbatim}
\clearpage

\section{Testing}


Make sure the \code{target/} directory is exported by your NFS server
by adding the following line to \code{/etc/exports}:

\begin{verbatim}
/tftpboot/core-image-minimal	*(rw,sync,no_subtree_check,no_root_squash)
\end{verbatim}

And restart your NFS server.

\begin{verbatim}
sudo service nfs-kernel-server restart
\end{verbatim}

You need a little different \code{uSetup.txt}. There should be a working \code{uSetup.txt}
in the \code{$HOME/felabs/sysdev/thirdparty/data} directory. \footnote{If you have built a
Yocto you will also get {\bf MLO} and {\bf u-boot.img}. They do not contain the patch to use {\bf uSetup.txt}}

The system should boot and give you a login prompt.

Use \code{root}. Password will not be needed.

If the system boots OK, a few files have been created.
Check in the files using git on your host. (YOu may have to change the permissions on some files).

You can use the commands \code{poweroff} or \code{reboot} to stop the system.

\clearpage
\section{uSetup.txt}

Note: Lines split, needs to be on a single line in the file.

\begin{verbatim}
ipaddr=192.168.0.100
serverip=192.168.0.1
loadaddr=0x80200000
fdtaddr=0x88000000
HOME=/home/ulf
bootdir=/boot
bootfile=uImage

console=ttyO0,115200n8
nfsopts=nolock
optargs=video=HDMI-A-1

setpath=setenv rootpath /tftpboot/${image}
setup_ip=setenv ip ${ipaddr}:${serverip}:${gatewayip}:${netmask}:${hostname}::off

tftp_kernel=run setpath ; tftp ${loadaddr} ${rootpath}/${bootdir}/${bootfile}
tftp_dtb=run setpath    ; tftp ${fdtaddr}  ${rootpath}/${bootdir}/${fdtfile}

mmcargs=setenv bootargs console=${console} ${optargs} root=${mmcroot} \
  rootfstype=${mmcrootfstype} rootwait
mmcrootfstype=squashfs
nandboot=echo NAND boot disabled

bootzImage=if test "${bootfile}" = "zImage"; then \
  bootz ${loadaddr} - ${fdtaddr}; fi
bootuImage=if test "${bootfile}" = "uImage"; then \
  bootm ${loadaddr} - ${fdtaddr}; fi
bootkernel=run bootzImage ; run bootuImage

netargs=setenv bootargs console=${console} ${optargs} \
  root=/dev/nfs nfsroot=${serverip}:/tftpboot/${image},${nfsopts} rw ip=${ipaddr}
netargs=run setpath     ; run setup_ip ; setenv bootargs console=${console} \
  ${optargs} root=/dev/nfs nfsroot=${serverip}:${rootpath},${nfsopts} rw ip=${ip}
netboot=echo Booting from network ...; run findfdt; setenv autoload no; \
  run tftp_kernel ; run tftp_dtb ; run netargs; bootm ${loadaddr} - ${fdtaddr}

image=core-image-minimal
br=setenv         image buildroot          ; setenv bootfile zImage ; run bootcmd
dynamic=setenv    image busybox.dynamic    ; setenv bootfile zImage ; run bootcmd
static=setenv     image busybox.static     ; setenv bootfile zImage ; run bootcmd
thirdparty=setenv image thirdparty         ; setenv bootfile zImage ; run bootcmd
minimal=setenv    image core-image-minimal ; setenv bootfile uImage ; run bootcmd
base=setenv       image core-image-base    ; setenv bootfile uImage ; run bootcmd
cato=setenv       image core-image-cato    ; setenv bootfile uImage ; run bootcmd

bootcmd=run findfdt ; run tftp_kernel tftp_dtb netargs bootkernel
\end{verbatim}



\clearpage

\section{zlib}

\code{Zlib} is a compression/decompression library available at
\url{http://www.zlib.net/}. Download version 1.2.8, and extract it in
\code{$HOME/felabs/sysdev/thirdparty/}.

By looking at the \code{configure} script, we see that this configure
script has not been generated by \code{autoconf} (otherwise it would
contain a sentence like {\em Generated by GNU Autoconf
  2.62}). Moreover, the project doesn't use automake since there are
no Makefile.am files. So zlib uses a custom build system, not a build
system based on the classical autotools.

Let's try to configure and build zlib:

\begin{verbatim}
./configure
make
\end{verbatim}

You can see that the files are getting compiled with gcc, which
generates code for x86 and not for the target platform. This is
obviously not what we want, so we tell the configure script to use the
ARM cross-compiler by setting {\bf CC}. This is done by our toolchain script
so we need to run this before \code{./configure}.

Enter the \code{zlib} source directory.

\begin{verbatim}
source ../../toolchain.sh
./configure
\end{verbatim}

\begin{verbatim}
# To impose specific compiler or flags or
# install directory, use for example:
#    prefix=$HOME CC=cc CFLAGS="-O4" ./configure
\end{verbatim}

Now when you compile with make, the cross-compiler is used. Look at
the result of compiling: a set of object files, a file \code{libz.a}
and set of \code{libz.so*} files.

The \code{libz.a} file is the static version of the library. It has
been generated using the following command:

\begin{verbatim}
ar rc libz.a adler32.o compress.o crc32.o gzio.o uncompr.o deflate.o \
      trees.o zutil.o inflate.o infback.o inftrees.o inffast.o
\end{verbatim}

It can be used to compile applications linked statically with the zlib
library, as shown by the compilation of the example program:

\begin{verbatim}
${CROSS_COMPILE}gcc -O3 -DUSE_MMAP -o example example.o -L. libz.a
\end{verbatim}

In addition to this static library, there is also a dynamic version of
the library, the \code{libz.so*} files. The shared library itself is
\code{libz.so.1.2.8}, it has been generated by the following command
line:

\begin{verbatim}
${CROSS_COMPILE}gcc -shared -Wl,-soname,libz.so.1 -o libz.so.1.2.8 \
              adler32.o compress.o crc32.o gzio.o uncompr.o  \
              deflate.o trees.o zutil.o inflate.o infback.o  \
              inftrees.o inffast.o
\end{verbatim}

And creates symbolic links \code{libz.so} and \code{libz.so.1}:

\begin{verbatim}
ln -s libz.so.1.2.8 libz.so
ln -s libz.so.1.2.8 libz.so.1
\end{verbatim}

These symlinks are needed for two different reasons:

\begin{itemize}
\item \code{libz.so} is used at compile time when you want to compile
  an application that is dynamically linked against the library. To do
  so, you pass the \code{-lLIBNAME} option to the compiler, which will
  look for a file named \code{lib<LIBNAME>.so}. In our case, the
  compilation option is \code{-lz} and the name of the library file is
  \code{libz.so}. So, the \code{libz.so} symlink is needed at compile
  time;
\item \code{libz.so.1} is needed because it is the {\em SONAME} of the
  library. {\em SONAME} stands for {\em Shared Object Name}. It is the
  name of the library as it will be stored in applications linked
  against this library. It means that at runtime, the dynamic loader
  will look for exactly this name when looking for the shared
  library. So this symbolic link is needed at runtime.
\end{itemize}

To know what's the {\em SONAME} of a library, you can use:
\begin{verbatim}
${CROSS_COMPILE}readelf -d libz.so.1.2.8
\end{verbatim}

and look at the \code{(SONAME)} line. You'll also see that this
library needs the C library, because of the \code{(NEEDED)} line on
\code{libc.so.0}.

The mechanism of \code{SONAME} allows to change the library without
recompiling the applications linked with this library. Let's say that
a security problem is found in zlib 1.2.8, and fixed in the next
release 1.2.6. You can recompile the library, install it on your
target system, change the link \code{libz.so.1} so that it points to
\code{libz.so.1.2.6} and restart your applications. And it will work,
because your applications don't look specifically for
\code{libz.so.1.2.8} but for the {\em SONAME}
\code{libz.so.1}. However, it also means that as a library developer,
if you break the ABI of the library, you must change the {\em SONAME}:
change from \code{libz.so.1} to \code{libz.so.2}.

Finally, the last step is to tell the configure script where the
library is going to be installed. Most configure scripts consider that
the installation prefix is \code{/usr/local/} (so that the library is
installed in \code{/usr/local/lib}, the headers in
\code{/usr/local/include}, etc.). But in our system, we simply want
the libraries to be installed in the \code{/usr} prefix, so let's tell
the configure script about this:

\begin{verbatim}
./configure --prefix=/usr
make
\end{verbatim}

For the zlib library, this option may not change anything to the
resulting binaries, but for safety, it is always recommended to make
sure that the prefix matches where your library will be running on the
target system.

Do not confuse the {\em prefix} (where the application or library will
be running on the target system) from the location where the
application or library will be installed on your host while building
the root filesystem. For example, zlib will be installed in
\code{$HOME/felabs/sysdev/thirdparty/target/usr/lib/} because
this is the directory where we are building the root filesystem, but
once our target system will be running, it will see zlib in
\code{/usr/lib}. The prefix corresponds to the path in the target
system and {\bf never} on the host. So, one should {\bf never} pass a
prefix like \code{$HOME/felabs/sysdev/thirdparty/target/usr},
otherwise at runtime, the application or library may look for files
inside this directory on the target system, which obviously doesn't
exist! By default, most build systems will install the application or
library in the given prefix (\code{/usr} or \code{/usr/local}), but
with most build systems (including {\em autotools}), the installation
prefix can be overriden, and be different from the configuration
prefix.

First, let's make the installation in the {\em staging} space:
\begin{verbatim}
make DESTDIR=/home/ulf/felabs/sysdev/thirdparty/staging install
\end{verbatim}

Now look at what has been installed by zlib:
\begin{itemize}
\item A manpage in \code{/usr/share/man}
\item A pkgconfig file in \code{/usr/lib/pkgconfig}. We'll come back to these
  later
\item The shared and static versions of the library in \code{/usr/lib}
\item The headers in \code{/usr/include}
\end{itemize}

Finally, let's install the library in the {\em target} space:

\begin{enumerate}
\item Create the \code{target/usr/lib} directory, it will contain the
  stripped version of the library
\item Copy the dynamic version of the library. Only \code{libz.so.1} and \code{libz.so.1.2.8} are needed, since \code{libz.so.1} is the {\em SONAME} of the library and \code{libz.so.1.2.8} is the real binary:\\
  \code{cp -a libz.so.1* ../target/usr/lib}
\item Strip the library:\\
  \code{${CROSS_COMPILE}strip ../target/usr/lib/libz.so.1.2.8}
\end{enumerate}

Ok, we're done with zlib!
\clearpage

\section{Libpng}

Download libpng from its official website at
\url{http://www.libpng.org/pub/png/libpng.html}. We tested the lab
with version 1.4.3. Please stick to this version as newer versions are
incompatible with the DirectFB version we use in this lab.

Once uncompressed, we quickly discover that the libpng build system is
based on the {\em autotools}, so we will work with a regular configure
script.

As we've seen previously, if we just run \code{./configure}, the build
system will use the native compiler to build the library, which is not
what we want. So let's tell the build system to use the
cross-compiler:

\begin{verbatim}
source ../../toolchain.sh
./configure
\end{verbatim}

Quickly, you should get an error saying:

\begin{verbatim}
configure: error: cannot run C compiled programs.
If you meant to cross compile, use `--host'.
See `config.log' for more details.
If you look at config.log, you quickly understand what's going on:
configure:2942: checking for C compiler default output file name
configure:2964: arm-linux-gcc    conftest.c  >&5
configure:2968: $? = 0
configure:3006: result: a.out
configure:3023: checking whether the C compiler works
configure:3033: ./a.out
./configure: line 3035: ./a.out: cannot execute binary file
\end{verbatim}

The configure script compiles a binary with the cross-compiler and
then tries to run it on the development workstation. Obviously, it
cannot work, and the system says that it
\code{cannot execute binary file}. The job of the configure script is
to test the configuration of the system. To do so, it tries to compile
and run a few sample applications to test if this library is
available, if this compiler option is supported, etc. But in our case,
running the test examples is definitely not possible. We need to tell
the configure script that we are cross-compiling, and this can be done
using the \code{--build} and \code{--host} options, as described in
the help of the configure script:

\begin{verbatim}
System types:
  --build=BUILD	configure for building on BUILD [guessed]
  --host=HOST	cross-compile to build programs to run on HOST [BUILD]
\end{verbatim}

The \code{--build} option allows to specify on which system the
package is built, while the \code{--host} option allows to specify on
which system the package will run. By default, the value of the
\code{--build} option is guessed and the value of \code{--host} is the
same as the value of the \code{--build} option. The value is guessed
using the \code{./config.guess} script, which on your system should
return \code{i686-pc-linux-gnu}. See
\url{http://www.gnu.org/software/autoconf/manual/html_node/Specifying-Names.html}
for more details on these options.

\clearpage

So, let's override the value of the \code{--host} option:

\begin{verbatim}
./configure --host=arm-linux
\end{verbatim}


This time, the \code{./configure} completes, but there is a problem.

The configure script tries to compile an application against {\em zlib}. 
{\em libpng} uses the {\em zlib} library, so the \code{configure} script wants to make
sure this library is already installed. Unfortunately, the \code{ld}
linker find the library in the toolchain, and not the one we compiled. 
So, let's tell the linker where to
look for libraries using the \code{-L} option followed by the
directory where our libraries are (in \code{staging/usr/lib}). This
\code{-L} option can be passed to the linker by using the
\code{LDFLAGS} at configure time, as told by the help text of the
configure script:

\begin{verbatim}
  LDFLAGS       linker flags, e.g. -L<lib dir> if you have
                libraries in a nonstandard directory <lib dir>
\end{verbatim}

Let's use this \code{LDFLAGS} variable:

\begin{verbatim}
export LDFLAGS=-L$HOME/felabs/sysdev/thirdparty/staging/usr/lib
./configure --host=arm-linux
\end{verbatim}

Let's also specify the prefix, so that the library is compiled to be
installed in \code{/usr} and not \code{/usr/local}:

\begin{verbatim}
./configure --host=arm-linux --prefix=/usr
\end{verbatim}

Of course, since {\em libpng} uses the {\em zlib} library, it includes
its header file! So we need to tell the C compiler where the headers
can be found: there are not in the default directory
\code{/usr/include/}, but in the \code{/usr/include} directory of our
{\em staging} space. The help text of the configure script says:

\begin{verbatim}
  CPPFLAGS              C/C++/Objective C preprocessor flags,
                        e.g. -I<include dir> if you have headers
                        in a nonstandard directory <include dir>
\end{verbatim}

Let's use it:

\begin{verbatim}
export CPPFLAGS=-I$HOME/felabs/sysdev/thirdparty/staging/usr/include
./configure --host=arm-linux --prefix=/usr
\end{verbatim}

Then, run the compilation with make. Hopefully, it works!

Let's now begin the installation process.  Before really installing in
the staging directory, let's install in a dummy directory, to see
what's going to be installed (this dummy directory will not be used
afterwards, it is only to verify what will be installed before
polluting the staging space):

\begin{verbatim}
make DESTDIR=/tmp/libpng/ install
\end{verbatim}

The \code{DESTDIR} variable can be used with all Makefiles based on
automake. It allows to override the installation directory: instead of
being installed in the configuration-prefix, the files will be
installed in \code{DESTDIR/configuration-prefix}.

Now, let's see what has been installed in \code{/tmp/libpng/}:

\begin{verbatim}
./usr/lib/libpng.la                     -> libpng14.la
./usr/lib/libpng14.a
./usr/lib/libpng14.la
./usr/lib/libpng14.so                   -> libpng14.so.14.3.0
./usr/lib/libpng14.so.14                -> libpng14.so.14.3.0
./usr/lib/libpng14.so.14.3.0
./usr/lib/libpng.a                      -> libpng14.a
./usr/lib/libpng.la                     -> libpng14.la
./usr/lib/libpng.so                     -> libpng14.so
./usr/lib/pkgconfig/libpng.pc           -> libpng14.pc
./usr/lib/pkgconfig/libpng14.pc
./usr/share/man/man5/png.5
./usr/share/man/man3/libpngpf.3
./usr/share/man/man3/libpng.3
./usr/include/pngconf.h                 -> libpng14/pngconf.h
./usr/include/png.h                     -> libpng14/png.h
./usr/include/libpng14/pngconf.h
./usr/include/libpng14/png.h
./usr/bin/libpng-config                 -> libpng14-config
./usr/bin/libpng14-config
\end{verbatim}

So, we have:
\begin{itemize}

\item The library, with many symbolic links

  \begin{itemize}
  \item \code{libpng14.so.14.3.0}, the binary of the current version of
    library
  \item \code{libpng14.so.14}, a symbolic link to
    \code{libpng14.so.14.3.0}, so that applications using
    \code{libpng14.so.14} as the {\em SONAME} of the library will find
    nit and use the current version
  \item \code{libpng14.so} is a symbolic link to
    \code{libpng14.so.14.3.0}. So it points to the current version of
    the library, so that new applications linked with \code{-lpng14}
    will use the current version of the library \code{libpng.so} is a
    symbolic link to libpng14.so. So applications linked with
    \code{-lpng} will be linked with the current version of the
    library (and not the obsolete one since we don't want anymore to
    link applications against the obsolete version!)
  \item \code{libpng14.a} is a static version of the library
  \item \code{libpng.a} is a symbolic link to \code{libpng14.a}, so
    that applications statically linked with \code{libpng.a} will in
    fact use the current version of the library
  \item \code{libpng14.la} is a configuration file generated by {\em
      libtool} which gives configuration details for the library. It
    will be used to compile applications and libraries that rely on
    libpng.
  \item \code{libpng.la} is a symbolic link to \code{libpng14.la}: we
    want to use the current version for new applications, once again.
  \end{itemize}

\item The {\em pkg-config} files, in \code{/usr/lib/pkgconfig/}. These
  configuration files are used by the pkg-config tool that we will
  cover later. They describe how to link new applications against the
  library.

\item The manual pages in \code{/usr/share/man/}, explaining how to use the
  library.

\item The header files, in \code{/usr/include/}, needed to compile new
  applications or libraries against {\em libpng}. They define the
  interface to {\em libpng}. There are symbolic links so that one can
  choose between the following solutions:

  \begin{itemize}

  \item Use \code{#include <png.h>} in the source code and compile with
    the default compiler flags

  \item Use \code{#include <png.h>} in the source code and compile
    with \code{-I/usr/include/libpng14}

  \item Use \code{#include <libpng14/png.h>} in the source and compile
    with the default compiler flags

  \end{itemize}

\item The \code{/usr/bin/libpng14-config} tool and its symbolic link
  \code{/usr/bin/libpng-config}. This tool is a small shell script
  that gives configuration information about the libraries, needed to
  know how to compile applications/libraries against libpng. This
  mechanism based on shell scripts is now being superseded by {\em
    pkg-config}, but as old applications or libraries may rely on it,
  it is kept for compatibility.

\end{itemize}

Now, let's make the installation in the {\em staging} space:

\begin{verbatim}
make DESTDIR=/home/ulf/felabs/sysdev/thirdparty/staging/ install
\end{verbatim}

Then, let's install only the necessary files in the {\em target}
space, manually:

\begin{verbatim}
cd ..
sudo cp -a staging/usr/lib/libpng14.so.* target/usr/lib
${CROSS_COMPILE}strip target/usr/lib/libpng14.so.14.3.0
\end{verbatim}

And we're finally done with libpng!

\section{libjpeg}

Now, let's work on {\em libjpeg}. Download it from
\url{http://www.ijg.org/files/jpegsrc.v8.tar.gz} and extract it.

Configuring {\em libjpeg} is very similar to the configuration of the
previous libraries:

To save time in the future, we will use a modified \code{toolchain.sh}.
Copy the file to the \code{thirdparty} directory and add the following lines
with the corretc user of course.

\begin{verbatim}
export LDFLAGS=-L/home/ulf/felabs/sysdev/thirdparty/staging/usr/lib
export CPPFLAGS=-I/home/ulf/felabs/sysdev/thirdparty/staging/usr/include
\end{verbatim}

You do not want to use the \code{$HOME} variable, since sometimes you
run the toolchain.sh script from the \code{root} user, and
then they would point at the wrong location.
You do need to replace \code{ulf} with your own username.

\begin{verbatim}
. ../toolchain.sh
./configure --host=arm-linux --prefix=/usr
\end{verbatim}

Of course, compile the library:

\begin{verbatim}
make
\end{verbatim}

Installation to the {\em staging} space can be done using the
classical \code{DESTDIR} mechanism:

\begin{verbatim}
sudo make DESTDIR=/home/ulf/felabs/sysdev/thirdparty/staging/ install
\end{verbatim}

And finally, install manually the only needed files at runtime in the
{\em target} space:

\begin{verbatim}
cd ..
sudo cp -a staging/usr/lib/libjpeg.so.8* target/usr/lib/
${CROSS_COMPILE}strip target/usr/lib/libjpeg.so.8.0.0
\end{verbatim}

Done with libjpeg!

\clearpage

\section{FreeType}

The {\em FreeType} library is the next step. Grab the tarball from
\url{http://www.freetype.org}. We tested the lab with version 2.4.2
but more other versions may also work. Uncompress the tarball.

The FreeType build system is a nice example of what can be done with a
good usage of the autotools. Cross-compiling FreeType is very
easy. First, the configure step:

\begin{verbatim}
source ../toolchain.sh
./configure	--host=arm-linux --prefix=/usr
\end{verbatim}

Then, compile the library:

\begin{verbatim}
make
\end{verbatim}

Install it in the {\em staging} space:

\begin{verbatim}
sudo make DESTDIR=/home/ulf/felabs/sysdev/thirdparty/staging/ install
\end{verbatim}

Obviously change the user to your own username.

And install only the required files in the {\em target} space:

\begin{verbatim}
cd ..
sudo cp -a staging/usr/lib/libfreetype.so.6* target/usr/lib/
${CROSS_COMPILE}strip target/usr/lib/libfreetype.so.6.6.0
\end{verbatim}

Done with FreeType!

\clearpage

\section{DirectFB}

Finally, with {\em zlib}, {\em libpng}, {\em jpeg} and {\em FreeType},
all the dependencies of DirectFB are ready. We can now build the
DirectFB library itself. Download it from the official website, at
\url{http://www.directfb.org/}. We tested version 1.4.5 of the
library. As usual, extract the tarball.

Before configuring DirectFB, let's have a look at the available
options by running 

\begin{verbatim}
./configure --help
\end{verbatim}

A lot of options are available. We see that:

\begin{itemize}
\item Support for Fbdev (the Linux framebuffer) is automatically
  detected, so that's fine;
\item Support for PNG, JPEG and FreeType is enabled by default, so
  that's fine;
\item We should specify a value for \code{--with-gfxdrivers}. The
  hardware emulated by QEMU doesn't have any accelerated driver in
  DirectFB, so we'll pass \code{--with-gfxdrivers=none};
\item We should specify a value for \code{--with-inputdrivers}. We'll
  need keyboard (for the keyboard) and linuxinput to support the Linux
  Input subsystem. So we'll pass
  \code{--with-inputdrivers=keyboard,linuxinput}
\end{itemize}

So, let's begin with a configure line like:

\begin{verbatim}
source ../toolchain.sh
./configure --host=arm-linux --prefix=/usr --with-gfxdrivers=none \
        --with-inputdrivers=keyboard,linuxinput
\end{verbatim}

Ok, now at the end of the configure, we get:

\begin{verbatim}
JPEG             yes  -ljpeg
PNG              yes  -I/opt/poky/sysroot/<...> -lpng12
[...]
FreeType2        yes  -I/opt/poky/sysroot/<...> -lfreetype
\end{verbatim}

It found the JPEG library properly, but for libpng and freetype, it
has added \code{-I} options that points to the libpng and freetype libraries
installed in our SDK and not the one of the target. This is not
correct!

In fact, the DirectFB configure script uses the {\em pkg-config}
system to get the configuration parameters to link the library against
libpng and FreeType. By default, {\em pkg-config} looks in
\code{/usr/lib/pkgconfig/} for \code{.pc} files, and because the
\code{libfreetype6-dev} and \code{libpng12-dev} packages are already
installed in the \code{core-image-sato} SDK, then the configure script of DirectFB
found the libpng and FreeType libraries there!

If it wasn't part of the SDK, then {\em pkg-config} would have found the host libraries.

This is one of the biggest issue with cross-compilation: mixing host
and target libraries, because build systems have a tendency to look
for libraries in the default paths. In our case, if
\code{libfreetype6-dev} was not installed on the host, nor in the SDK{\em pkg-config}, then the
\code{/usr/lib/pkgconfig/freetype2.pc} file wouldn't exist, and the
configure script of DirectFB would have said something like {\em
  Sorry, can't find FreeType}.

So, now, we must tell {\em pkg-config} to look inside the
\code{/usr/lib/pkgconfig/} directory of our {\em staging} space. This
is done through the \code{PKG_CONFIG_PATH} environment variable, as
explained in the manual page of \code{pkg-config}.

Moreover, the \code{.pc} files contain references to paths. For
example, in
\code{$HOME/felabs/sysdev/thirdparty/staging/usr/lib/pkgconfig/freetype2.pc},
we can see:

\begin{verbatim}
prefix=/usr
exec_prefix=${prefix}
libdir=${exec_prefix}/lib
includedir=${prefix}/include
[...]
Libs: -L${libdir} -lfreetype
Cflags: -I${includedir}/freetype2 -I${includedir}
\end{verbatim}

So we must tell \code{pkg-config} that these paths are not absolute,
but relative to our {\em staging} space. This can be done using the
\code{PKG_CONFIG_SYSROOT_DIR} environment variable.

Then, let's run the configuration of DirectFB again, passing the
\code{PKG_CONFIG_PATH} and \code{PKG_CONFIG_SYSROOT_DIR} environment
variables:

Add the following lines to your thirdparty \code{toolchain.sh}, modifying the user.

\begin{verbatim}
export PKG_CONFIG_PATH=/home/ulf/felabs/sysdev/thirdparty/staging/usr/lib/pkgconfig
export PKG_CONFIG_SYSROOT_DIR=/home/ulf/felabs/sysdev/thirdparty/staging
\end{verbatim}

The source the new configuration and configure:

\begin{verbatim}
. ../toolchain.sh
./configure --host=arm-linux --prefix=/usr --with-gfxdrivers=none \
	--with-inputdrivers=keyboard,linuxinput
\end{verbatim}

Ok, now, the lines related to Libpng and FreeType 2 looks much better:

\footnotesize
\begin{verbatim}
PNG       yes -I/home/<user>/felabs/sysdev/thirdparty/staging/usr/include/libpng14 -lpng14
FreeType2 yes -I/home/<user>/felabs/sysdev/thirdparty/staging/usr/include/freetype2 -lfreetype
\end{verbatim}
\normalsize

If we try building DirectFB now, it will complete the build, but there may be one
remaining problem. If configure for some reason finds X11, we have not added that to our image.

If DirectFB has enabled X11, it fails during the build, complaining
that \code{X11/Xlib.h} and other related header files cannot be
found. In fact, if you look back the \code{./configure} script output,
you in that case see:

\begin{verbatim}
X11 support		yes		-lX11 -lXext
\end{verbatim}

Because X11 was installed in the serach path, DirectFB \code{./configure}
script thought that it should enable support for it. But we won't have
X11 on our system, so we have to disable it explicitly. In the
\code{./configure --help} output, one can see:

\begin{verbatim}
--enable-x11		build with X11 support [default=auto]
\end{verbatim}

If X11 is enabled, we have to run the configuration again with the same arguments, and
add \code{--disable-x11} to them.

The build now goes further, but still fails with another error:

\begin{verbatim}
/usr/lib/libfreetype.so: could not read symbols: File in wrong format
\end{verbatim}

As you can read from the above command line, the Makefile is trying to
feed an x86 binary (\code{/usr/lib/libfreetype.so}) to your ARM
toolchain. Instead, it should have been using
\code{usr/lib/libfreetype.so} found in your staging environment.

This happens because the {\em libtool} \code{.la} files in your
staging area need to be fixed to describe the right paths in this
staging area. So, in the .la files, replace \code{libdir='/usr/lib'}
by
\code{libdir='/home/<user>/felabs/sysdev/thirdparty/staging/usr/lib'}. Restart
the build again, preferably from scratch (\code{make clean} then
\code{make}) to be sure everything is fine.

Finally, it builds!

Now, install DirectFB to the {\em staging} space using:

\begin{verbatim}
make DESTDIR=/home/ulf/felabs/sysdev/thirdparty/staging/ install
\end{verbatim}

And so the installation in the {\em target} space:

\begin{itemize}

\item First, the libraries:
\small
\begin{verbatim}
cd ..
sudo su
source ./toolchain.sh
cp -a staging/usr/lib/libdirect-1.4.so.5* target/usr/lib
cp -a staging/usr/lib/libdirectfb-1.4.so.5* target/usr/lib
cp -a staging/usr/lib/libfusion-1.4.so.5* target/usr/lib
${CROSS_COMPILE}strip target/usr/lib/libdirect-1.4.so.5.0.0
${CROSS_COMPILE}strip target/usr/lib/libdirectfb-1.4.so.5.0.0
${CROSS_COMPILE}strip target/usr/lib/libfusion-1.4.so.5.0.0
exit
\end{verbatim}
\normalsize

\item Then, the plugins that are dynamically loaded by DirectFB. We
  first copy the whole \code{/usr/lib/directfb-1.4-5/} directory, then
  remove the useless files (\code{.la}) and finally strip the
  \code{.so} files:

\small
\begin{verbatim}
sudo su
source toolchain.sh
cp -a staging/usr/lib/directfb-1.4-5/ target/usr/lib
find target/usr/lib/directfb-1.4-5/ -name '*.la' -exec rm {} \;
find target/usr/lib/directfb-1.4-5/ -name '*.so' -exec ${CROSS_COMPILE}strip {} \;
exit
\end{verbatim}
\normalsize

\end{itemize}
\clearpage
\section{DirectFB examples}

To test that our DirectFB installation works, we will use the example
applications provided by the DirectFB project. Start by downloading
the tarball at
\url{http://www.directfb.org/downloads/Extras/DirectFB-examples-1.2.0.tar.gz}
and extract it.

Then, we configure it just as we configured DirectFB:

\small
\begin{verbatim}
source toolchain.sh
cd DirectFB-examples-1.2.0
./configure --host=arm-linux --prefix=/usr
\end{verbatim}
\normalsize

Then, compile it with \code{make}.  It should succeed.

For the installation, as DirectFB examples are only applications and
not libraries, we don't really need them in the {\em staging} space,
but only in the {\em target} space. So we'll directly install in the
{\em target} space using the \code{install-strip} make target. This
make target is usually available with autotools based build
systems. In addition to the destination directory (\code{DESTDIR}
variable), we must also tell which strip program should be used, since
stripping is an architecture-dependent operation (\code{STRIP}
variable):

\begin{verbatim}
sudo su
source ../toolchain.sh
make STRIP=${CROSS_COMPILE}strip \
     DESTDIR=/home/ulf/felabs/sysdev/thirdparty/target/ install-strip
\end{verbatim}

\section{Final setup}

If you try to run the DirectFB examples now, they will fail to run, 
because of missing libraries.
The \code{core-image-minimal} filesystem includes some needed libraries
like \code{libpthread} and \code{libdl}.

\code{libpthread} is used to implement threads.

\code{libdl}, is used to dynamically load libraries during
application execution. 

\code{libsysfs} and \code{libgcc_s} are missing.

Add the following line to the end of the thirdparty \code{toolchain.sh}

\begin{verbatim}
export TOOLCHAIN_SYSROOT=$(${CROSS_COMPILE}gcc -print-sysroot)
\end{verbatim}

So let's add the missing libraries to the target:

\begin{verbatim}
cp -a $TOOLCHAIN_SYSROOT/lib/libsysfs* target/lib
cp -a $TOOLCHAIN_SYSROOT/lib/libgcc_s* target/lib
\end{verbatim}

Now, the application should no longer complain about missing
libraries. 

Other problems that could occur are missing device files.

In a busybox barebone, you would need \code{/dev/fb0}
which can be created by:

\begin{verbatim}
sudo mknod target/dev/fb0 c 29 0
\end{verbatim}

\code{Yocto} which is used by the \code{core-image-minimal}
used \code{udev} which dynamically creates the device files
at run time, and is a more modern approach.

Now, you can try and run the \code{df_andi} application!

Check that you do not get any error messages.

Without a screen, you will not be able to do a lot,
but you may be able to borrow one of the few screens
with HDMI input that are available.

If you want to try this at home, you will need a microHDMI to HDMI cable.
